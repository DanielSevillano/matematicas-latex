\chapter{Inferencia bayesiana}
\section{Teorema de Bayes}
\begin{theorem}[Teorema de Bayes]
    Sea $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad.
    Sea $\{A_1, \dots, A_n\} \subset \mathcal{A}$ una partición de $\Omega$ y sea $B \in \mathcal{A}$ tal que $P(B) > 0$ y del que se conocen $P(B|A_i)$, para $i = 1, \dots, n$.
    Entonces
    $$P(A_i|B) = \frac{P(B|A_i)P(A_i)}{\sum_{j=1}^n P(B|A_j)P(A_j)}, \quad \forall i = 1, \dots, n$$
    donde:
    \begin{itemize}
        \item $P(A_j)$, $j = 1, \dots, n$, se llaman probabilidades a priori.
        \item $P(B|A_j)$, $j = 1, \dots, n$, se llaman verosimilitudes.
        \item $P(A_j|B)$, $j= 1, \dots, n$, se llaman probabilidades a posteriori.
    \end{itemize}

    Esta se conoce como la fórmula de Bayes.
\end{theorem}

\begin{remark}
    Las probabilidades a posteriori son proporcionales al producto de verosimilitudes y probabilidades a priori.
    $$P(A_i|B) \propto P(B|A_i)P(A_i)$$
\end{remark}

\begin{example}
    Una caja contiene dos monedas: una moneda legal $M_1$ y otra con una cara en cada lado $M_2$.

    En primer lugar, se selecciona una de las dos monedas al azar, se lanza y sale cara.
    Veamos cuál es la probabilidad de que la moneda lanzada sea la legal.

    Para ello definimos los sucesos:
    \begin{itemize}
        \item $C_i$: en el lanzamiento $i$ sale cara.
        \item $F_i$: en el lanzamiento $i$ sale cruz.
    \end{itemize}

    Usamos el teorema de Bayes:
    \begin{center}
        \begin{tabular}{| c | c | c |}
            \hline
            Probabilidad a priori  & Verosimilitudes            & Probabilidad a posteriori  \\
            \hline
            $P(M_1) = \frac{1}{2}$ & $P(C_1|M_1) = \frac{1}{2}$ & $P(M_1|C_1) = \frac{1}{3}$ \\
            $P(M_2) = \frac{1}{2}$ & $P(C_1|M_2) = 1$           & $P(M_2|C_1) = \frac{2}{3}$ \\
            \hline
        \end{tabular}
    \end{center}

    Lanzamos de nuevo la moneda elegida y se obtiene otra cara.
    Veamos cuál es la probabilidad de que la moneda lanzada sea la legal.

    Podemos usar el carácter secuencial del teorema de Bayes y usar los resultados anteriores.

    \begin{center}
        \begin{tabular}{| c | c | c |}
            \hline
            Probabilidad a priori      & Verosimilitudes            & Probabilidad a posteriori           \\
            \hline
            $P(M_1|C_1) = \frac{1}{3}$ & $P(C_2|M_1) = \frac{1}{2}$ & $P(M_1|C_1 \cap C_2) = \frac{1}{5}$ \\
            $P(M_2|C_1) = \frac{2}{3}$ & $P(C_2|M_2) = 1$           & $P(M_2|C_1 \cap C_2) = \frac{4}{5}$ \\
            \hline
        \end{tabular}
    \end{center}
\end{example}

\section{Teorema de Bayes generalizado}
\begin{theorem}[Teorema de Bayes generalizado]
    Sean $\vec{x} = (x_1, \dots, x_n)$ una muestra y $\theta$ una variable aleatoria.
    Sea $f_\theta$ la distribución a priori y $f(\vec{x}|\theta)$ la función de verosimilitud.
    Entonces:
    $$f(\theta|\vec{x}) = \frac{f(\vec{x}|\theta)f_\theta(\theta)}{f(\vec{x})}$$
    donde:
    $$f(\vec{x}) = \begin{cases}
            \sum_{i=1}^n f(\vec{x}|\theta_i)f_\theta(\theta_i)    & \text{si es discreta} \\
            \int_\Theta f(\vec{x}, \theta)f_\theta(\theta)d\theta & \text{si es continua}
        \end{cases}$$
\end{theorem}

\begin{remark}
    Para los clásicos, $\theta$ es un parámetro fijo y desconocido.
    En cambio, para los bayesianos $\theta$ es una variable aleatoria.
\end{remark}

\begin{example}
    Supongamos que tenemos una moneda y queremos estimar la probabilidad $p$ de obtener cara.
    Supongamos que nuestras creencias a priori sobre $p$ se pueden describir por una distribución uniforme en $(0, 1)$.
    Realizamos el experimento de tirar la moneda 12 veces y obtenemos 9 caras y 3 cruces.

    Definimos la variable aleatoria:
    $$X = \begin{cases}
            1 & \text{si sale cara } (C) \\
            0 & \text{si sale cruz } (F)
        \end{cases}, \quad X|p \sim Ber(p)$$
    Queremos estimar $P(C) = P(X = 1) = p$ a partir de nuestra muestra $\vec{x} = (x_1, \dots, x_{12})$, com $\sum_{i=1}^{12} x_i = 9$.

    Como $p \sim U(0, 1)$, su distribución a priori es $f(p) = 1$ si $p \in (0, 1)$.
    Calculamos la función de verosimilitud:
    $$L(\vec{x}, p) = \prod_{i=1}^{12} f(x_i|p) = \prod_{i=1}^{12} p^{x_i}(1-p)^{1-x_i} = p^9(1-p)^3$$
    Podemos hallar la distribución a posteriori:
    $$f(p|\vec{x}) \propto p^9(1-p)^3 \Rightarrow p|\vec{x} \sim Be(10, 4)$$
\end{example}

\begin{note}
    Si $X \sim Be(p, q)$ beta, entonces:
    $$f_X(x) \propto x^{p-1}(1-x)^{q-1}$$
\end{note}

\section{Familias de distribución conjugadas}
Las familias de distribución conjugadas son aquellas en las que las distribuciones a priori y a posteriori son de la misma familia.

\subsection*{Muestras de la distribución Bernoulli}
Sean $x_i|\theta \sim Ber(\theta)$ y $\theta \sim Be(p, q)$.
Su distribución a priori es:
$$f_\theta(\theta) \propto \theta^{p-1}(1-\theta)^{q-1}, \quad \theta \in (0, 1)$$
Dada una muestra $\vec{x}$, calculamos la función de verosimilitud:
$$L(\vec{x}, \theta) = \prod_{i=1}^n f(x_i|\theta) \propto \theta^{\sum_{i=1}^n x_i}(1-\theta)^{n-\sum_{i=1}^n x_i}$$
Luego la distribución a posteriori es:
\begin{align*}
    f(\theta|\vec{x}) & \propto f_\theta(\theta)L(\vec{x}, \theta) \propto \theta^{p+\sum_{i=1}^n x_i-1}(1-\theta)^{n+q-\sum_{i=1}^n x_i+1} \\
                      & \Rightarrow \theta|\vec{x} \sim Be\left(p+\sum_{i=1}^n x_i, n+q-\sum_{i=1}^n x_i\right)
\end{align*}
Por tanto, la beta es una familia conjugada respecto de muestras de la Bernoulli.

\subsection*{Muestras de la distribución de Poisson}
Sean $x_i|\lambda \sim Po(\lambda)$ y $\lambda \sim Ga(a, p)$.
Su distribución a priori es:
$$f_\lambda(\lambda) = \frac{a^p}{\Gamma(p)}e^{-a\lambda}\lambda^{p-1}, \quad \lambda, a, p > 0$$
Dada una muestra $\vec{x}$, calculamos la función de verosimilitud:
$$L(\vec{x}, \lambda) = \prod_{i=1}^n f(x_i|\lambda) \propto \prod_{i=1}^n e^{-\lambda}\lambda^{x_i} = e^{-n\lambda}\lambda^{\sum_{i=1}^n x_i}$$
Luego la distribución a posteriori es:
\begin{align*}
    f(\lambda|\vec{x}) & \propto f_\lambda(\lambda)L(\vec{x}, \lambda) \propto e^{-(a+n)\lambda}\lambda^{\sum_{i=1}^n x_i+p-1} \\
                       & \Rightarrow \lambda|\vec{x} \sim Ga(a+n, p+\sum_{i=1}^n x_i)
\end{align*}
Por tanto, la gamma es una familia conjugada respecto de muestras de la Poisson.

\subsection*{Muestras de la distribución normal}
\begin{lemma}
    $$A(z-a)^2 + B(z-b)^2 = (A+B)\left(z - \frac{Aa+Bb}{A+B}\right)^2 + \frac{AB}{A+B}(a-b)^2$$
\end{lemma}

\subsubsection*{Media desconocida y precisión conocida}
Sea $x_i|\mu \sim N(\mu, p)$ con media $\mu$ desconocida y precisión $p$ conocida y sea $\mu \sim N(m_0, p_0)$.
Su distribución a priori es:
$$f_\mu(\mu) = \frac{\sqrt{p_0}}{\sqrt{2\pi}} e^{\frac{p_0}{2}(\mu-m_0)^2} \propto e^{-\frac{p_0}{2}(\mu-m_0)^2}$$
Dada una muestra $\vec{x}$, calculamos la función de verosimilitud:
$$L(\vec{x}, \mu) = \prod_{i=1}^n f(x_i|\mu) \propto \prod_{i=1}^n e^{-\frac{p}{2}(x_i-\mu)^2} = e^{-\frac{p}{2}\sum_{i=1}^n (x_i-\mu)^2}$$

\begin{note}
    \begin{align*}
        \sum_{i=1}^n (x_i-\mu)^2 & = \sum_{i=1}^n (x_i-\bar{x}+\bar{x}-\mu)^2 =                                                   \\
                                 & = \sum_{i=1}^n (x_i-\bar{x})^2 + n(\bar{x}-\mu)^2 + 2(\bar{x}-\mu)\sum_{i=1}^n (x_i-\bar{x}) = \\
                                 & = (n-1)s^2 + n(\bar{x}-\mu)^2
    \end{align*}
\end{note}

Así que:
$$L(\vec{x}, \mu) = e^{-\frac{p}{2}((n-1)s^2+n(\bar{x}-\mu)^2)} \propto e^{-\frac{np}{2}(\bar{x}-\mu)^2}$$
Luego la distribución a posteriori es:
$$f(\mu|\vec{x}) \propto f_\mu(\mu)L(\vec{x}, \mu) \propto e^{-\frac{p}{2}(\mu-m_0)^2}e^{-\frac{np}{2}(\bar{x}-\mu)^2} = e^{-\frac{1}{2}(p_0(\mu-m_0)^2+np(\bar{x}-\mu)^2)}$$
Usando el lema previo, queda:
\begin{align*}
    f(\mu, \vec{x}) & \propto e^{-\frac{1}{2}(a(\mu-b)^2+c)} \propto e^{-\frac{a}{2}(\mu-b)^2} \\
                    & \Rightarrow \mu|\vec{x} \sim N(b, pr = a)
\end{align*}
donde
$$a = p_0+np, \quad b = \frac{p_0m_0+np\bar{x}}{p_0+np}$$
Por tanto, la normal es una familia conjugada respecto de muestras de la normal con media desconocida y precisión conocida.

\subsubsection*{Media conocida y precisión desconocida}
Sea $x_i|\tau \sim N(\mu, \tau)$ y sea $\tau \sim Ga(a_0, p_0)$.
Su distribución a priori es:
$$f_\tau(\tau) = \frac{a_0^p}{\Gamma(p_0)}e^{-a_0\tau}\tau^{p_0-1}, \quad \tau, a_0, p_0 > 0$$
Dada una muestra $\vec{x}$, calculamos la función de verosimilitud:
$$L(\vec{x}, \tau) = \prod_{i=1}^n f(x_i|\tau) \propto \prod_{i=1}^n \sqrt{\tau}e^{-\frac{\tau}{2}(x_i-\mu)^2} = \tau^{\frac{n}{2}}e^{-\frac{\tau}{2}\sum_{i=1}^n(x_i-\mu)^2}$$
Luego la distribución a posteriori es:
\begin{align*}
    f(\tau|\vec{x}) & \propto f_\tau(\tau)L(\vec{x}, \tau) \propto \tau^{\frac{n}{2}+p_0-1}e^{-\tau\left(a_0+\frac{1}{2}\sum_{i=1}^n(x_i-\mu)^2\right)} \\
                    & \Rightarrow \tau|\vec{x} \sim Ga(a_n, p_n)
\end{align*}
donde
$$a_n = a_0 + \frac{1}{2}\sum_{i=1}^n(x_i-\mu)^2, \quad p_n = \frac{n}{2}+p_0$$
Por tanto, la gamma es una familia conjugada respecto de muestras de la normal con media conocida y precisión desconocida.

\subsubsection*{Media conocida y varianza desconocida}
\begin{definition}
    Sea $X \sim Ga(a, p)$, consideramos $Y = \frac{1}{X}$.
    Entonces $Y \sim GaI(a, p)$ gamma invertida.
    Su función de densidad es:
    $$f_Y(y) = \frac{a^p}{\Gamma(p)} e^{-\frac{a}{y}} y^{-(p+1)}, \quad y > 0$$
\end{definition}

Sea $x_i|\sigma^2 \sim N(\mu, \sigma^2)$ con varianza $\sigma^2$ desconocida y sea $\sigma^2 \sim GaI(a_0, p_0)$.
Su distribución a priori es:
$$f_{\sigma^2}(\sigma^2) = \frac{a_0^{p_0}}{\Gamma(p_0)}e^{-\frac{a_0}{\sigma^2}}(\sigma^2)^{-(p_0+1)}, \quad a_0, p_0 > 0$$
Dada una muestra $\vec{x}$, calculamos la función de verosimilitud:
$$L(\vec{x}, \sigma^2) = \prod_{i=1}^n f(x_i|\sigma^2) \propto \prod_{i=1}^n \frac{1}{\sqrt{\sigma^2}}e^{-\frac{1}{2\sigma^2}(x_i-\mu)^2} = (\sigma^2)^{-\frac{n}{2}}e^{-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2}$$
Luego la distribución a posteriori es:
\begin{align*}
    f(\sigma^2|\vec{x}) & \propto f_{\sigma^2}(\sigma^2)L(\vec{x}, \sigma^2) \propto (\sigma^2)^{-\left(p_0+\frac{n}{2}+1\right)}e^{-\frac{1}{\sigma^2}}\left(a_0+\frac{1}{2}\sum_{i=1}^n(x_i-\mu)^2\right) \\
                        & \Rightarrow \sigma^2|\vec{x} \sim GaI(a_n, p_n)
\end{align*}
donde
$$a_n = a_0 + \frac{1}{2}\sum_{i=1}^n(x_i-\mu)^2, \quad p_n = p_0 + \frac{n}{2}$$
Por tanto, la gamma invertida es una familia conjugada respecto de muestras de la normal con media conocida y varianza desconocida.

\subsubsection*{Media y precisión desconocidas}
\begin{definition}
    Decimos que $(\mu, \tau) \sin NGa(m_0, \tau_0, a_0, p_0)$ normal gamma, con $m_0 \in \mathbb{R}, \tau_0, a_0, p_0 > 0$, si:
    $$\mu|\tau \sim N(m_0, pr = \tau\tau_0) \text{ y } \tau \sim Ga(a_0, p_0), \quad \mu \in \mathbb{R}, \tau > 0$$
    Su función de densidad es:
    $$f(\mu, \tau) = \frac{\sqrt{\tau_0}}{\sqrt{2\pi}} \frac{a_0^{p_0}}{\Gamma(p_0)} \tau^{p_0 - \frac{1}{2}} e^{-\tau \left(a_0 + \frac{\tau_0}{2}(\mu-m_0)^2\right)}$$
\end{definition}

\begin{definition}
    Si $T \sim t_n$ y $X = \mu + \frac{1}{\sqrt{p}}T$, entonces $X \sim t(\mu, p, n)$, donde $\mu$ es la media y $p$ es el parámetro de escala.
    Su función de densidad es:
    $$f_X(x) = \frac{\Gamma\left(\frac{n+1}{2}\right)\sqrt{p}}{\Gamma\left(\frac{1}{2}\right)\Gamma\left(\frac{n}{2}\right)\sqrt{n}} \left(1 + \frac{p}{n}(x-\mu)^2\right)^{-\frac{n+1}{2}}$$
    Verifica que:
    $$E(X) = \mu, \quad V(X) = \frac{1}{p} \frac{n}{n-2}$$
\end{definition}

\begin{remark}
    La distribución $t_1$ se llama distribución de Cauchy.
    Además:
    $$t_n \xrightarrow[n \to \infty]{} N(0, 1)$$
\end{remark}

\begin{theorem}
    Si $(\mu, \tau) \sim NGa(m_0, \tau_0, a_0, p_0)$, entonces:
    $$\mu \sim t\left(m_0, \frac{p_0\tau_0}{a_0}, 2p_0\right)$$
\end{theorem}

\begin{corollary}[Génesis bayesiana de la $t$ de Student]
    $$\begin{cases}
            \mu|\tau \sim N(0, \tau) \\
            \tau \sim Ga\left(\frac{n}{2}, \frac{n}{2}\right)
        \end{cases} \Rightarrow \mu \sim t(0, 1, n) \equiv t_n$$
\end{corollary}

Sean $x_i|\mu, \tau \sim N(\mu, \tau)$ y $(\mu, \tau) \sim NGa(m_0, \tau_0, a_0, p_0)$.
Se puede comprobar que la normal gamma es una familia conjugada respecto de muestras de la normal con media y precisión desconocidas.

\section{Distribuciones a priori no informativas}
\begin{definition}
    La información de Fisher para $\theta$ se define como:
    $$J(\theta) = -E\left(\frac{\partial^2 \log(f(x|\theta))}{\partial\theta^2}\right)$$
\end{definition}

\begin{proposition}[Regla de Jeffreys]
    $$f_\theta(\theta) \propto \sqrt{J(\theta)}$$
\end{proposition}

\begin{remark}
    La regla de Jeffreys no da densidades en general.
    A aquellas que no son densidades se les llama densidades impropias.
\end{remark}

\subsection*{Muestras de la distribución Bernoulli}
Sea $x|\theta \sim Ber(\theta)$.
Entonces:
$$f(x|\theta) = \theta^x(1-\theta)^{1-x}, \quad x = 0, 1, 0 < \theta < 1$$
Calculamos:
\begin{align*}
    \log(f(x|\theta))                                      & = x\log(\theta) + (1-x)\log(1-\theta)               \\
    \frac{\partial \log(f(x|\theta))}{\partial \theta}     & = \frac{x}{\theta} - (1-x)\frac{1}{1-\theta}        \\
    \frac{\partial^2 \log(f(x|\theta))}{\partial \theta^2} & = -\frac{x}{\theta^2} - (1-x)\frac{1}{(1-\theta)^2}
\end{align*}
Luego la información de Fisher para $\theta$ es:
\begin{align*}
    J(\theta) & = E\left(\frac{x}{\theta^2} + \frac{1-x}{(1-\theta)^2}\right) = \frac{1}{\theta^2}E(X) + \frac{1}{(1-\theta)^2}E(1-x) = \\
              & = \frac{1}{\theta^2}\theta + \frac{1}{(1-\theta)^2}(1-\theta) = \frac{1}{\theta(1-\theta)}
\end{align*}
Por tanto:
$$f_\theta(\theta) \propto \sqrt{J(\theta)} \propto \theta^{-\frac{1}{2}}(1-\theta)^{-\frac{1}{2}} \Rightarrow \theta \sim Be\left(\frac{1}{2}, \frac{1}{2}\right)$$

\subsection*{Muestras de la distribución de Poisson}
Sea $x|\lambda \sim Po(\lambda)$.
Entonces:
$$f(x|\lambda) = \frac{e^{-\lambda}\lambda^x}{x!} \propto e^{-\lambda}\lambda^x, \quad x = 0, 1, \lambda > 0$$
Calculamos:
\begin{align*}
    \log(f(x|\lambda))                                       & \propto -\lambda + x\log(\lambda) \\
    \frac{\partial \log(f(x|\lambda))}{\partial \lambda}     & \propto -1 + \frac{x}{\lambda}    \\
    \frac{\partial^2 \log(f(x|\lambda))}{\partial \lambda^2} & \propto -\frac{x}{\lambda^2}
\end{align*}
Luego la información de Fisher para $\lambda$ es:
$$J(\lambda) = E\left(\frac{x}{\lambda^2}\right) = \frac{1}{\lambda^2}E(x) = \frac{1}{\lambda^2}\frac{1}{\lambda} = \frac{1}{\lambda}$$
Por tanto:
$$f_\lambda(\lambda) \propto \frac{1}{\sqrt{\lambda}}$$
Observamos que $f_\lambda$ no es una densidad.

\subsection*{Muestras de la distribución normal}
\subsubsection*{Media desconocida y precisión conocida}
Sea $x|\mu \sim N(\mu, p)$.
Entonces:
$$f(x|\mu) = \frac{\sqrt{p}}{\sqrt{2\pi}}e^{-\frac{p}{2}(x-\mu)^2} \propto e^{-\frac{p}{2}(x-\mu)^2}$$
Calculamos:
\begin{align*}
    \log(f(x|\mu))                                   & \propto -\frac{p}{2}(x-\mu)^2 \\
    \frac{\partial \log(f(x|\mu))}{\partial \mu}     & \propto p(x-\mu)              \\
    \frac{\partial^2 \log(f(x|\mu))}{\partial \mu^2} & \propto -p \propto -1         \\
\end{align*}
Luego la información de Fisher para $\mu$ es:
$$J(\mu) \propto E(1) = 1$$
Por tanto:
$$f_\mu(\mu) \propto \sqrt{J(\mu)} \propto 1$$
Observamos que $f_\mu$ no es una densidad.

\subsubsection*{Media conocida y desviación típica desconocida}
Sea $x|\sigma \sim N(\mu, \sigma)$.
Entonces:
$$f(x|\sigma) = \frac{1}{\sqrt{1\pi\sigma^2}}e^{-\frac{p}{2}(x-\mu)^2} \propto e^{-\frac{p}{2}(x-\mu)^2}$$
Calculamos:
\begin{align*}
    \log(f(x|\mu))                                         & \propto -\log(\sigma) - \frac{1}{2\sigma^2}(x-\mu)^2     \\
    \frac{\partial \log(f(x|\sigma))}{\partial \sigma}     & \propto -\frac{1}{\sigma} + (x-\mu)^2\frac{1}{\sigma^3}  \\
    \frac{\partial^2 \log(f(x|\sigma))}{\partial \sigma^2} & \propto \frac{1}{\sigma^2} - 3\frac{(x-\mu)^2}{\sigma^4}
\end{align*}
Luego la información de Fisher para $\sigma$ es:
\begin{align*}
    J(\sigma) & \propto E\left(-\frac{1}{\sigma^2} + 3\frac{(x-\mu)^2}{\sigma^4}\right) = -\frac{-1}{\sigma^2} + \frac{3}{\sigma^4}E((x-\mu)^2) = -\frac{-1}{\sigma^2} + \frac{3}{\sigma^4}\sigma^2 = \\
              & = \frac{2}{\sigma^2} \propto \frac{1}{\sigma^2}
\end{align*}
Por tanto:
$$f_\sigma(\sigma) \propto \frac{1}{\sigma}$$
Observamos que $f_\sigma$ no es una densidad.

\subsubsection*{Media conocida y varianza desconocida}
Sea $x|\sigma^2 \sim N(\mu, \sigma^2)$.
Entonces:
$$f_{\sigma^2}(\sigma^2) = \frac{1}{\sigma^2}$$

\subsubsection*{Media conocida y precisión desconocida}
Sea $x|\tau \sim N(\mu, \tau)$.
Entonces:
$$f_\tau(\tau) \propto \frac{1}{\tau}$$

\subsubsection*{Media y desviación típica desconocidas}
Sea $x|\mu, \sigma \sim N(\mu, \sigma)$.
Entonces:
$$f(\mu, \sigma) = f_\mu(\mu)f_\sigma(\sigma) \propto \frac{1}{\sigma}$$

\subsubsection*{Media y varianza desconocidas}
Sea $x|\mu, \sigma^2 \sim N(\mu, \sigma^2)$.
Entonces:
$$f(\mu, \sigma^2) = f_\mu(\mu)f_{\sigma^2}(\sigma^2) \propto \frac{1}{\sigma^2}$$

\subsubsection*{Media y precisión desconocidas}
Sea $x|\mu, \tau \sim N(\mu, \tau)$.
Entonces:
$$f(\mu, \tau) = f_\mu(\mu)f_\tau(\tau) \propto \frac{1}{\tau}$$

\begin{remark}[Regla de oro]
    Todo sale de la distribución a priori.
\end{remark}

\section{Estimación puntual}
La estimación puntual bayesiana es un problema de decisión.

Una función de pérdida es una función $L: \Theta \times \Theta \to \mathbb{R}$ donde $L(\theta, t)$ es la pérdida si estimamos el parámetro por $t$, siendo $\theta$ su verdadero valor.
Las funciones de pérdida más usuales son:
\begin{itemize}
    \item Función de pérdida cuadrática:
          $$L(\theta, t) = (\theta-t)^2$$
    \item Función de pérdida valor absoluto:
          $$L(\theta, t) = |\theta-t|$$
    \item Función de pérdida 0-1:
          $$L(\theta, t) = \begin{cases}
                  0 & \text{si } |\theta-t| \leq \varepsilon \\
                  1 & \text{si } |\theta-t| > \varepsilon
              \end{cases}$$
\end{itemize}

Queremos minimizar respecto de $t$ la función pero el valor de $\theta$ es desconocido y no podemos calcular la pérdida.
Así que minimizamos la esperanza de la función de pérdida a posteriori $E(L(\theta, t)|\vec{x})$.
Elegimos $\hat{\theta}$ tal que:
$$\min_{t \in \Theta} E(L(\theta, t)|\vec{x}) = \min_{t \in \Theta} \int_\Theta L(\theta, t)f(\theta|\vec{x})d\theta = E(L(\theta, \vec{\theta}))$$

\begin{example}
    Tomamos $L(\theta, t) = (\theta-t)^2$.
    \begin{align*}
        \psi(t)  & = E(L(\theta, t)|\vec{x}) = \int_\Theta (\theta-t)^2f(\theta|\vec{x})d\theta =                                                             \\
                 & = \int_\Theta \theta^2f(\theta|\vec{x})d\theta + t^2\int_\Theta f(\theta|\vec{x})d\theta - 2t\int_\Theta \theta f(\theta|\vec{x})d\theta = \\
                 & = \int_\Theta \theta^2f(\theta|\vec{x})d\theta + t^2 - 2tE(\theta|\vec{x})                                                                 \\
        \psi'(t) & = 2t - E(\theta|\vec{x})
    \end{align*}
    Hallamos el mímimo de $\psi$:
    $$\psi'(t) = 0 \Leftrightarrow t = E(\theta|\vec{x}) \Rightarrow \hat{\theta} = E(\theta|\vec{x})$$
\end{example}

De forma análoga podemos concluir:
\begin{itemize}
    \item El estimador bayesiano de $\theta$ bajo la función de pérdida cuadrática es la media a posteriori de $\theta$.
    \item El estimador bayesiano de $\theta$ bajo la función de pérdida valor absoluto es la media a posteriori de $\theta$.
    \item El estimador bayesiano de $\theta$ bajo la función de pérdida 0-1 es la media a posteriori de $\theta$.
\end{itemize}

\begin{remark}
    La media a posteriori es una media ponderada de la media a priori y del estimador de máxima verosimilitud.
    $$E(\theta|\vec{x}) = \omega E(\theta) + (1-\omega)\hat{\theta}_{EMV}$$
\end{remark}

\section{Intervalos de credibilidad}
Un intervalo de credibilidad para $\theta$ de contenido probabilístico $1-\alpha$ es un intervalo $(a, b)$ tal que:
$$P(a < \theta|\vec{x} < b) = 1-\alpha$$

\begin{definition}
    Un región $R$ es de máxima densidad a posteriori de $\theta$ con contenido probabilístico $1-\alpha$ si:
    \begin{enumerate}
        \item $P((\theta|\vec{x}) \in R) = 1-\alpha$.
        \item Si $\theta_1 \in R$ y $\theta_2 \notin R$, entonces $f(\theta_1|\vec{x}) > f(\theta_2|\vec{x})$.
    \end{enumerate}
    Se escribe $MDP_{1-\alpha}$.
\end{definition}

\begin{note}
    Si la distribución de $\theta|\vec{x}$ es unimodal, la región de máxima densidad a posteriori de contenido probabilístico $1-\alpha$ para $\theta$ es un intervalo $(a, b)$ tal que:
    \begin{enumerate}
        \item $P(a < \theta|\vec{x} < b) = 1-\alpha$.
        \item $f_{\theta|\vec{x}}(a) = f_{\theta|\vec{x}}(b) \Leftrightarrow f(a|\vec{x}) = f(b|\vec{x})$.
    \end{enumerate}
\end{note}

\section{Contrastes de hipótesis}
\subsection*{Contraste unilateral a la derecha}
$$\begin{cases}
        H_0: \theta \leq \theta_0 \\
        H_1: \theta > \theta_0
    \end{cases}$$
Calculamos:
\begin{align*}
    P(H_0|\vec{x}) & = P(\theta \leq \theta_0|\vec{x}) \\
    P(H_1|\vec{x}) & = P(\theta > \theta_0|\vec{x})
\end{align*}
Entonces:
\begin{itemize}
    \item Si $P(H_0|\vec{x}) > P(H_1|\vec{x})$, aceptamos $H_0$.
    \item En caso contrario, rechazamos $H_0$.
\end{itemize}

\subsection*{Contraste unilateral a la izquierda}
$$\begin{cases}
        H_0: \theta \leq \theta_0 \\
        H_1: \theta > \theta_0
    \end{cases}$$
Calculamos:
\begin{align*}
    P(H_0|\vec{x}) & = P(\theta \geq \theta_0|\vec{x}) \\
    P(H_1|\vec{x}) & = P(\theta < \theta_0|\vec{x})
\end{align*}
Entonces:
\begin{itemize}
    \item Si $P(H_0|\vec{x}) > P(H_1|\vec{x})$, aceptamos $H_0$.
    \item En caso contrario, rechazamos $H_0$.
\end{itemize}

\subsection*{Contraste bilateral}
$$\begin{cases}
        H_0: \theta = \theta_0 \\
        H_1: \theta \neq \theta_0
    \end{cases}$$
\begin{itemize}
    \item Si $\theta_0 \in MDP_{1-\alpha}(\theta|\vec{x})$, aceptamos $H_0$.
    \item En caso contrario, rechazamos $H_0$.
\end{itemize}

\section{Distribuciones predictivas}
Sea $\vec{x} = (x_1, \dots, x_n)$, definimos la distribución predictiva como:
$$f(x_{n+1}|\vec{x}) = \int_\Theta f(x_{n+1}|\theta)f(\theta|\vec{x})d\theta$$

\begin{example}
    Consideramos los tres siguientes casos:
    \begin{enumerate}
        \item A una anciana se le somete a diez pruebas para ver si acierta o no si en una taza de té con leche se ha echado antes el té o la leche.
              Acierta las diez pruebas.
        \item A un experto en música se le somete a diez pruebas para ver si acierta si una pieza musical es de Mozart o de Haydn.
              Acierta en las diez ocasiones.
        \item A un borracho se le somete a diez pruebas para ver si acierta si en el lanzamiento de una moneda sale cara o cruz.
              Acierta en las diez ocasiones.
    \end{enumerate}
    Estudiemos qué ocurrirá si realizamos en cada uno de estos casos una prueba más.

    Sea $X \sim Ber(\theta)$, con:
    $$X = \begin{cases}
            1 & \text{si acierta} \\
            0 & \text{si falla}
        \end{cases}, \quad \theta = P(X=1)$$
    Entonces:
    $$f(x_i|\theta) \propto \theta^{x_i}(1-\theta)^{10-x_i}$$
    Sea $\vec{x} = (x_1, \dots, x_{10}) = (1, \dots, 1)$, calculamos la función de verosimilitud:
    $$L(\vec{x}, \theta) = \prod_{i=1}^{10} f(x_i|\theta) \propto \theta^{\sum_{i=1}^{10} x_i}(1-\theta)^{10-\sum_{i=1}^{10} x_i} = \theta^{10}$$

    Sea $\theta \sim Be(p, q)$.
    Su distribución a priori es:
    $$f_\theta(\theta) = \frac{\Gamma(p+q)}{\Gamma(p)\Gamma(q)} \theta^{p-1}(1-\theta)^{q-1}, \quad 0 < \theta < 1$$
    Luego la distribución a posteriori es:
    \begin{align*}
        f(\theta|\vec{x}) & \propto f_\theta(\theta)L(\vec{x}, \theta) \propto \theta^{p-1+10}(1-\theta)^{q-1} = \theta^{p+q}(1-\theta)^{q-1} \\
                          & \Rightarrow \theta|\vec{x} \sim Be(p+10, q)
    \end{align*}

    Una estimación puntual de $\theta$ con la función de pérdida cuadrática es:
    $$E(\theta|\vec{x}) = \frac{p+10}{p+q+10}$$

    Hallamos la distribución predictiva:
    \begin{align*}
        P(x_{11}=1|\vec{x}) & = \int_0^1 P(x_{11}=1|\theta)f(\theta|\vec{x})d\theta =                                               \\
                            & = \int_0^1 \theta \frac{\Gamma(p+10+q)}{\Gamma(p+10)\Gamma(q)} \theta^{p+10}(1-\theta)^{q-1}d\theta = \\
                            & = \frac{\Gamma(p+10+q)}{\Gamma(p+10)\Gamma(q)} \int_0^1 \theta^{p+10}(1-\theta)^{q-1}d\theta
    \end{align*}
    Observamos que el interior de la integral es la función de densidad de una distribución $Be(p+11, q)$ salvo constantes.
    Por tanto:
    $$P(x_{11}=1|\vec{x}) = \frac{\Gamma(p+10+q)}{\Gamma(p+10)\Gamma(q)} \frac{\Gamma(p+11)\Gamma(q)}{\Gamma(p+q+11)} = \frac{p+10}{p+q+10}$$
    Luego $P(x_{11}=0|\vec{x}) = \frac{q}{p+q+10}$.

    Analizamos cada caso:
    \begin{enumerate}
        \item Podemos usar una distribución no informativa según la regla de Jeffreys, como $p = q = \frac{1}{2}$.
              En este caso:
              $$P(x_{11}|\vec{x}) = \frac{1/2+10}{1/2+1/2+10} = \frac{21}{22} \approx 0,9545$$
        \item Podemos tomar $p, q \to \infty$, de forma que $\frac{p}{p+q} \xrightarrow[p, q \to \infty]{} 1$.
              En este caso:
              $$P(x_{11}|\vec{x}) = \frac{p+10}{p+q+10} \xrightarrow[p, q \to \infty]{} 1$$
        \item Podemos tomar $p = q \to \infty$.
              En este caso:
              $$P(x_{11}|\vec{x}) = \frac{p+10}{2p+10} \xrightarrow[p \to \infty]{} \frac{1}{2}$$
    \end{enumerate}

    La probabilidad de que en tres pruebas siguientes los resultados sean acierto, fallo y fallo, en ese orden, podemos calcularla como:
    \begin{align*}
        P(x_{11} = 1, x_{12} = 1, x_{13} = 0|\vec{x}) & = \int_0^1 P(x_{11} = 1, x_{12} = 1, x_{13} = 0|\theta)f(\theta|\vec{x})d\theta = \\
                                                      & = \int_0^1 \theta^2(1-\theta)f(\theta|\vec{x})d\theta
    \end{align*}

    La probabilidad de que en tres pruebas siguientes haya dos aciertos y un fallo, podemos calcularla como $3P(x_{11} = 1, x_{12} = 1, x_{13} = 0)$.

    En general, la probabilidad de que en las siguientes $m$ pruebas haya $r$ aciertos se calcula como $\binom{m}{r}P(x_{11} = 1, x_{12} = 1, x_{13} = 0)$.
\end{example}

\section{Análisis bayesiano para datos de Bernoulli}
Sea $x|\theta \sim Ber(\theta)$.
Estudiaremos el caso informativo con $\theta \sim Be(p, q)$.
Sabíamos que:
$$\theta|\vec{x} \sim Be\left(p+\sum_{i=1}^n x_i, n+q-\sum_{i=1}^n x_i\right)$$

Como por la regla de Jeffreys $\theta \sim Be\left(\frac{1}{2}, \frac{1}{2}\right)$, el caso no informativo es análogo con $p = q = \frac{1}{2}$.

\subsection*{Estimación puntual}
Analizamos la estimación bajo cada una de las funciones de pérdida usuales.
\begin{itemize}
    \item Si $L(\theta, t) = (\theta-t)^2$, entonces:
          $$\hat{\theta} = E(\theta|\vec{x}) = \frac{\sum_{i=1}^n x_i + p}{n+p+q}$$
    \item Si $L(\theta, t) = |\theta-t|$, entonces:
          $$\hat{\theta} = Me(\theta|\vec{x})$$
    \item Si $L(\theta, t) = \begin{cases}
                  0 & \text{si } |\theta-t| \leq \varepsilon \\
                  1 & \text{si } |\theta-t| > \varepsilon
              \end{cases}$, entonces:
          $$\hat{\theta} = Mo(\theta|\vec{x}) = \frac{\sum_{i=1}^n x_i + p-1}{n+p+q-2}$$
\end{itemize}

Vimos que la media a posteriori era una media ponderada de la media a priori y del estimador de máxima verosimilitud.
Es decir:
$$E(\theta|\vec{x}) = \omega E(\theta) + (1-\omega)\hat{\theta}_{EMV}$$
Calculamos los pesos:
$$\frac{\sum_{i=1}^n x_i + p}{n+p+q} = \omega\frac{p}{p+q} + (1-\omega)\frac{1}{n}\sum_{i=1}^n x_i \Rightarrow \omega = \frac{p+q}{n+p+q}$$
Observamos que:
$$\omega = \frac{p+q}{n+p+q} \xrightarrow[n \to \infty]{} 0,  \quad 1-\omega = \frac{n}{n+p+q} \xrightarrow[n \to \infty]{} 1$$
Es decir, en la media a posteriori tiene mayor influencia el estimador de máxima verosimilitud si tenemos muchos datos.

\subsection*{Intervalos de credibilidad}
Un intervalo de credibilidad para $\theta$ de contenido probabilístico $1-\alpha$ es un intervalo $(a, b)$ tal que:
$$P(a < \theta|\vec{x} < b) = \int_a^b f(\theta|\vec{x})d\theta = 1-\alpha$$

El intervalo de máxima densidad a posteriori de $\theta$ con contenido probabilístico $1-\alpha$ es un intervalo $(a, b)$ tal que:
\begin{enumerate}
    \item $P(a < \theta|\vec{x} < b) = 1-\alpha$.
    \item $f(a|\vec{x}) = f(b|\vec{x})$.
\end{enumerate}

\begin{note}
    El intervalo de máxima densidad a posteriori no se puede calcular a mano.
\end{note}

\subsection*{Distribución predictiva}
Calculamos la distribución predictiva.
\begin{align*}
     & P(x_{n+1} = 1|\vec{x}) = \int_0^1 P(x_{n+1} = 1|\theta)f(\theta|\vec{x})d\theta =                                                                                        \\
     & = \frac{\Gamma(n+p+q)}{\Gamma(\sum_{i=1}^n x_i + p)\Gamma(n - \sum_{i=1}^n x_i + q)} \int_0^1 \theta^{\sum_{i=1}^n x_i + p}(1-\theta)^{n - \sum_{i=1}^n x_i +q-1}d\theta
\end{align*}
Observamos que el interior de la integral es la función de densidad de una distribución $Be(\sum_{i=1}^n x_i + p+1, n - \sum_{i=1}^n x_i + q)$ salvo constantes.
Por tanto:
\begin{align*}
    P(x_{n+1} = 1|\vec{x}) & = \frac{\Gamma(n+p+q)\Gamma(\sum_{i=1}^n x_i+p+1)\Gamma(n - \sum_{i=1}^n x_i + q)}{\Gamma(\sum_{i=1}^n x_i + p)\Gamma(n - \sum_{i=1}^n x_i + q)\Gamma(n+p+q+1)} = \\
                           & = \frac{\sum_{i=1}^n x_i+p}{n+p+q}
\end{align*}

La probabilidad de que en las siguientes $m$ pruebas haya $r$ éxitos y $m-r$ fracasos se calcula como:
\begin{align*}
     & \binom{m}{r}P(x_{n+1} = \dots = x_{n+r} = 1, x_{n+r+1} = \dots = x_{n+m} = 0|\vec{x}) = \\
     & = \binom{m}{r} \int_0^1 \theta^r(1-\theta)^{m-r}f(\theta|\vec{x})d\theta
\end{align*}

\section{Análisis bayesiano para datos de Poisson}
Sea $x|\lambda \sim Po(\lambda)$.
Estudiaremos el caso informativo con $\lambda \sim Ga(a, p)$.
Sabíamos que:
\begin{align*}
    f_\lambda(\lambda) & = \frac{a^p}{\Gamma(p)} e^{-a\lambda}\lambda^{p-1}, \quad \lambda > 0 \\
    \lambda|\vec{x}    & \sim Ga(a+n, p+\sum_{i=1}^n x_i)
\end{align*}

Como por la regla de Jeffreys $f_\lambda(\lambda) \propto \lambda^{-\frac{1}{2}}$, el caso no informativo es análogo con $a = 0$ y $p = \frac{1}{2}$.

\subsection*{Estimación puntual}
Analizamos la estimación bajo la función de pérdida cuadrática:
$$\hat{\lambda} = E(\lambda|\vec{x}) = \frac{a+n}{\sum_{i=1}^n + p}$$

\subsection*{Intervalos de credibilidad}
Un intervalo de credibilidad para $\lambda$ de contenido probabilístico $1-\alpha$ es un intervalo $(\lambda_1, \lambda_2)$ tal que:
$$P(\lambda_1 < \lambda|\vec{x} < \lambda_2) = 1-\alpha$$

\begin{note}
    Si $X \sim Ga(a, p)$ entonces $2aX \sim \chi^2_{2p}$.
\end{note}

Así que:
$$2(a+n)\lambda|\vec{x} \sim \chi^2_{2(\sum_{i=1}^n x_i + p)}$$

Por tanto:
$$1-\alpha = P(\lambda_1 < \lambda|\vec{x} < \lambda_2) = P(2(a+n)\lambda_1 < \chi^2_{2(\sum_{i=1}^n x_i - p)} < 2(a+n)\lambda_2)$$

El intervalo de máxima densidad a posteriori de $\lambda$ con contenido probabilístico $1-\alpha$ es un intervalo $(\lambda_1, \lambda_2)$ tal que:
\begin{enumerate}
    \item $P(\lambda_1 < \lambda|\vec{x} < \lambda_2) = 1-\alpha$.
    \item $f(\lambda_1|\vec{x}) = f(\lambda_2|\vec{x})$.
\end{enumerate}

\begin{note}
    El intervalo de máxima densidad a posteriori no se puede calcular a mano.
\end{note}

\subsection*{Distribución predictiva}
Calculamos la distribución predictiva.
\begin{align*}
     & P(X_{n+1} = x_{n+1}|\vec{x}) = \int_0^\infty P(X_{n+1} = x_{n+1}|\lambda)f(\lambda|\vec{x})d\lambda =                                                         \\
     & = \frac{(a+n)^{\sum_{i=1}^n x_i + p}}{x_{n+1}!\Gamma(\sum_{i=1}^n x_i + p)} \int_0^\infty e^{-\lambda(a+n+1)\lambda^{x_n+1 + \sum_{i=1}^n x_i + p-1}}d\lambda
\end{align*}
Observamos que el interior de la integral es la función de densidad de una distribución $Ga(a+n+1, x_{n+1} + \sum_{i=1}^n x_i + p)$ salvo constantes.
Por tanto:
$$P(X_{n+1} = x_{n+1}|\vec{x}) = \frac{(a+n)^{\sum_{i=1}^n x_i + p}}{x_{n+1}!\Gamma(\sum_{i=1}^n x_i + p)} \frac{\Gamma(x_{n+1} + \sum_{i=1}^n x_i + p)}{(a+n+1)^{x_{n+1} + \sum_{i=1}^n x_i + p}}$$