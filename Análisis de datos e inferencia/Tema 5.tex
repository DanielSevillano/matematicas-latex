\chapter{Introducción a la inferencia no paramétrica}
\section{Introducción}
Hasta ahora los tests de hipótesis han sido utilizados para contrastar la veracidad de hipótesis acerca de los parámetros de la distribución de una población.
Sin embargo, en muchas ocasiones, es necesario emitir un juicio estadístico sobre la distribución poblacional en su conjunto.
Los problemas de este tipo que se plantean de manera habitual son los siguientes:
\begin{itemize}
    \item \textbf{Contrastes de bondad de ajuste.}
          Decidir, a la vista de una muestra aleatoria de una población, si puede admitirse que la distribución poblacional coincide con una cierta distribución dada o pertenece a un determinado tipo de distribuciones.
    \item \textbf{Contrastes de homogeneidad.}
          Analizar si varias muestras aleatorias provienen de poblaciones con la misma distribución teórica, de forma que puedan ser utilizadas conjuntamente para inferencias posteriores acerca de esta; o, por el contrario, son muestras de poblaciones con distinta distribución, que no pueden agruparse como información homogénea acerca de una única distribución.
    \item \textbf{Contrastes de independencia.}
          Estudiar, en el caso en que se observen dos o más características de los elementos de la población si las características observadas pueden considerarse independientes, y se puede proceder a su análisis por separado, o, por el contrario, existe relación estadística entre ellas.
\end{itemize}

\section{Contrastes de bondad de ajuste}
\subsection*{Primer caso}
Consideremos una muestra aleatoria $(X_1, \dots, X_n)$ de una variable aleatoria $X$ con distribución desconocida.
Para decidir si es razonable admitir que la distribucion de $X$ viene dada por un determinado modelo de probabilidad $P$, resolvemos el siguiente contraste de hipótesis:
$$\begin{cases}
        H_0: \text{ el modelo de probabilidad de } X \text{ es } P \\
        H_1: \text{ el modelo de probabilidad de } X \text{ no es } P
    \end{cases}$$

\begin{note}
    El modelo $P$ debe estar completamente especificado.
\end{note}

Para contrastar $H_0$ frente a $H_1$ hacemos una partición arbitraria del espacio muestral de la población en $k$ clases $A_1, \dots, A_k$.
Después, para cada $A_i$ consideramos las siguientes frecuencias absolutas:
\begin{itemize}
    \item $O_i$: frecuencia observada en $A_i$, número de elementos de la muestra que están en la clase $A_i$.
    \item $e_i$: frecuencia esperada de la clase $A_i$ si la hipótesis $H_0$ es cierta, $nP(A_i)$.
\end{itemize}

El estadístico que utilizaremos es:
$$\sum_{i=1}^k \frac{(O_i-e_i)^2}{e_i}$$
que tiene aproximadamente cuando $n$ es grande una distribución $\chi^2_{k-1}$ si $H_0$ es cierta.

Para que la aproximación sea razonablemente buena, además de tener una muestra suficientemente grande, es necesario que el valor esperado de cada clase sea suficientemente grande.
Si la muestra procede de $P$, es de esperar que haya valores parecidos para $O_i$ y $e_i$ y, por tanto, este estadístico debería tomar valores próximos a cero.

Rechazaremos $H_0$ a nivel de significación $\alpha$ si:
$$\sum_{i=1}^k \frac{(O_i-e_i)^2}{e_i} > \chi^2_{k-1, 1-\alpha}$$
En caso contrario, aceptaremos $H_0$ a nivel de significación $\alpha$.

\begin{example}
    Después de lanzar un dado 300 veces, se obtienen las siguientes frecuencias:
    \begin{center}
        \begin{tabular}{ | c | c c c c c c | }
            \hline
            Resultado  & 1  & 2  & 3  & 4  & 5  & 6  \\
            \hline
            Frecuencia & 43 & 49 & 56 & 45 & 66 & 41 \\
            \hline
        \end{tabular}
    \end{center}

    Veamos si se puede afirmar que el dado es regular a nivel de significación $\alpha = 0.05$.

    Disponemos de una muestra aleatoria de $n = 300$ lanzamientos de un dado.
    Para decidir si el dado es regular o no, llevamos a cabo un contraste de bondad de ajuste a nivel de significación $\alpha$:
    $$\begin{cases}
            H_0: \text{ El dado es regular: } P(1) = \dots = P(6) = \frac{1}{6} \\
            H_1: \text{ El dado es irregular}
        \end{cases}$$

    La tabla de frecuencias observadas y esperadas es:
    \begin{center}
        \begin{tabular}{| c | c c c c c c |}
            \hline
            $A_i$ & 1  & 2  & 3  & 4  & 5  & 6  \\
            \hline
            $O_i$ & 43 & 49 & 56 & 45 & 66 & 41 \\
            $e_i$ & 50 & 50 & 50 & 50 & 50 & 50 \\
            \hline
        \end{tabular}
    \end{center}
    donde las frecuencias esperadas bajo $H_0$ han sido calculadas como:
    $$e_i = nP(A_i) = 300 \frac{1}{6} = 50$$

    Usamos el estadístico de contraste:
    $$\sum_{i=1}^k \frac{(O_i-e_i)^2}{e_i}$$
    que tiene aproximadamente una distribución $\chi^2_{k-1}$ si $H_0$ es cierta.

    Rechazaremos $H_0$ a nivel de significación $\alpha$ si:
    $$\sum_{i=1}^k \frac{(O_i-e_i)^2}{e_i} > \chi^2_{k-1, 1-\alpha}$$
    En nuestro caso:
    $$\sum_{i=1}^6 \frac{(O_i-e_i)^2}{e_i} = 8.96, \quad \chi^2_{5, 0.95} = 11.07$$

    Por tanto, aceptamos $H_0$ a nivel de significación $\alpha = 0.05$, es decir, aceptamos que el dado es regular a nivel de significación $\alpha = 0.05$.
\end{example}

\begin{example}
    Nos dicen que un programa de ordenador genera observaciones de una distribucion $N(0, 1)$.
    Como no estamos seguros de ello, obtenemos una muestra aleatoria de 450 observaciones mediante dicho programa, obteniendo los siguientes resultados:
    \begin{itemize}
        \item 30 observaciones menores que -2.
        \item 80 observaciones entre -2 y -1.
        \item 140 observaciones entre -1 y 0.
        \item 110 observaciones entre 0 y 1.
        \item 60 observaciones entre 1 y 2.
        \item 30 observaciones mayores que 2.
    \end{itemize}
    Veamos si se puede aceptar que el programa funciona correctamente a nivel de significación $\alpha = 0.01$.

    Disponemos de una muestra aleatoria de $n = 450$ observaciones generadas por el programa.
    Los posibles resultados de estas observaciones se agrupan en seis clases:
    \begin{align*}
        A_1 & = (-\infty, -2) & A_2 & = (-2, -1)    \\
        A_3 & = (-1, 0)       & A_4 & = (0, 1)      \\
        A_5 & = (1, 2)        & A_6 & = (2, \infty)
    \end{align*}
    Para decidir si el programa funciona correctamente o no, llevamos a cabo un contraste de bondad de ajuste a nivel de significación $\alpha$:
    $$\begin{cases}
            H_0: \text{ El programa funciona correctamente: provienen de } N(0, 1) \\
            H_1: \text{ El programa no funciona correctamente}
        \end{cases}$$

    La tabla de frecuencias observadas y esperadas es:
    \begin{center}
        \begin{tabular}{| c | c c c c c c |}
            \hline
            $A_i$    & $(-\infty, -2)$ & $(-2, -1)$ & $(-1, 0)$ & $(0, 1)$ & $(1, 2)$ & $(2, \infty)$ \\
            \hline
            $O_i$    & 30              & 80         & 140       & 110      & 60       & 30            \\
            $P(A_i)$ & 0.0228          & 0.1359     & 0.3413    & 0.3413   & 0.1359   & 0.0228        \\
            $e_i$    & 10.26           & 61.155     & 153.585   & 154.585  & 61.155   & 10.26         \\
            \hline
        \end{tabular}
    \end{center}
    donde las frecuencias esperadas bajo $H_0$ han sido calculadas de la forma:
    $$e_i = nP(A_i) = 450P(A_i)$$
    y los valores $P(A_i)$ se han calculado a partir de la tabla de la función de distribucion de la normal estándar.

    Usamos el estadístico de contraste:
    $$\sum_{i=1}^k \frac{(O_i-e_i)^2}{e_i}$$
    que tiene aproximadamente una distribución $\chi^2_{k-1}$ si $H_0$ es cierta.

    Rechazaremos $H_0$ a nivel de significación $\alpha$ si:
    $$\sum_{i=1}^k \frac{(O_i-e_i)^2}{e_i} > \chi^2_{k-1, 1-\alpha}$$
    En nuestro caso:
    $$\sum_{i=1}^6 \frac{(O_i-e_i)^2}{e_i} = 95.358, \quad \chi^2_{5, 0.99} = 15.086$$

    Por tanto, rechazamos $H_0$ a nivel de significación $\alpha = 0.01$, es decir, podemos afirmar que el programa no funciona correctamente a nivel de significación $\alpha = 0.01$.
\end{example}

\subsection*{Segundo caso}
El contraste de bondad de ajuste se puede plantear también en una situación más general.
Consideremos una muestra aleatoria $(X_1, \dots, X_n)$ de una variable aleatoria $X$ con distribución desconocida.
Para decidir si es razonable admitir que la distribución de $X$ viene dada por algún modelo de probabilidad de una cierta familia $P_\theta$, con $\theta = (\theta_1, \dots, \theta_r)$, resolveremos el siguiente contraste de hipótesis:
$$\begin{cases}
        H_0: \text{ el modelo de probabilidad } X \text{ es de la familia } \{P_\theta: \theta \in \Theta\} \\
        H_0: \text{ el modelo de probabilidad } X \text{ no es de la familia } \{P_\theta: \theta \in \Theta\}
    \end{cases}$$

Para contrastar $H_0$ frente a $H_1$ hacemos nuevamente una partición arbitraria del espacio muestral de la población en $k$ clases $A_1, \dots, A_k$.
Después, para cada $A_i$ consideramos las siguientes frecuencias absolutas:
\begin{itemize}
    \item $O_i$: frecuencia observada en $A_i$, número de elementos de la muestra que están en la clase $A_i$.
    \item $e_i$: frecuencia esperada de la clase $A_i$ si la hipótesis $H_0$ es cierta, $nP_\theta(A_i) \approx nP_{\hat{\theta}}(A_i)$, donde $\hat{\theta}$ es el estimador de máxima verossimilitud de $\theta$.
\end{itemize}

El estadístico que utilizaremos es:
$$\sum_{i=1}^k \frac{(O_i-e_i)^2}{e_i}$$
que tiene aproximadamente cuando $n$ es grande una distribución $\chi^2_{k-r-1}$ si $H_0$ es cierta.

Rechazaremos $H_0$ a nivel de significación $\alpha$ si:
$$\sum_{i=1}^k \frac{(O_i-e_i)^2}{e_i} > \chi^2_{k-r-1, 1-\alpha}$$
En caso contrario, aceptaremos $H_0$ a nivel de significación $\alpha$.

% Ejemplo

\section{Contrastes de homogeneidad}
Supongamos que disponemos de $p$ muestras aleatorias independientes tomadas de $p$ poblaciones sobre una característica común $X$ a todas ellas:
\begin{align*}
    (X_{11}, \dots, X_{1n_1}) \\
    \dots                     \\
    (X_{p1}, \dots, X_{pn_p})
\end{align*}
con $n_1 + \dots + n_p = n$.

Queremos ver si, a la vista de las muestras obtenidas, es razonable admitir que todas las poblaciones tienen una distribucion común, es decir, si son poblaciones homogéneas.
Por tanto, tenemos el contraste:
$$\begin{cases}
        H_0: \text{ Las } p \text{ poblaciones tienen una distribucion común} \\
        H_1: \text{ Las } p \text{ poblaciones no tienen una distribucion común}
    \end{cases}$$

Para contrastar $H_0$ frente a $H_1$ hacemos nuevamente una partición arbitraria del espacio muestral común a las $p$ poblaciones en $k$ clases $A_1, \dots, A_k$.

Después, definimos para la clase $A_i$ y para la muestra de la población $j$-ésima:
\begin{itemize}
    \item $O_{ij}$: frecuencia observada en la clase $A_i$ con la muestra $j$-ésima.
    \item $e_{ij}$: frecuencia esperada en la clase $A_i$ con la muestra $j$-ésima si todas las poblaciones tienen la distribucion común $P$, $n_jP(A_i)$.
\end{itemize}

El estadístico utilizado es:
$$\sum_{j=1}^p \sum_{i=1}^k \frac{(O_{ij}-e_{ij})^2}{e_{ij}}$$
que tiene aproximadamente cuando $n$ es grande una distribucion $\chi^2_{(k-1)(p-1)}$ si $H_0$ es cierta.

Rechazaremos $H_0$ a nivel de significación $\alpha$ si:
$$\sum_{j=1}^p \sum_{i=1}^k \frac{(O_{ij}-e_{ij})^2}{e_{ij}} > \chi^2_{(k-1)(p-1), 1-\alpha}$$
En caso contrario, aceptaremos $H_0$ a nivel de significación $\alpha$.

% Ejemplo y problemas

\section{Contrastes de independencia}
Supongamos que queremos estudiar si dos características $X$ e $Y$ de una población están relacionadas o no.
Para hacer este estudio, obtenemos una muestra aleatoria de $n$ pares de valores de estas características:
$$((X_1, Y_1), \dots, (X_n, Y_n))$$
Queremos ver si, a la vista de la muestra, tiene sentido admitir que $X$ e $Y$ son independientes.
Por tanto, tenemos el contraste:
$$\begin{cases}
        H_0: X \text{ e } Y \text{ son independientes} \\
        H_1: X \text{ e } Y \text{ no son independientes}
    \end{cases}$$

Tomamos una partición arbitraria del espacio muestral en $kp$ clases:
$$A_1 \times B_1, \dots, A_k \times B_p$$
Estas $kp$ clases corresponden a tomar las clases $A_1, \dots, A_k$ para la característica $X$ y las clases $B_1, \dots, B_p$ para la característica $Y$.

Llamamos:
\begin{itemize}
    \item $O_{ij}$: frecuencia observada en la clase $A_i \times B_j$.
    \item $e_{ij}$: frecuencia esperada en la clase $A_i \times B_j$ si la hipótesis nula es cierta, $nP(A_i)P(B_j)$.
\end{itemize}

El estadístico utilizado es:
$$\sum_{j=1}^p \sum_{i=1}^k \frac{(O_{ij}-e_{ij})^2}{e_{ij}}$$
que tiene aproximadamente cuando $n$ es grande una distribucion $\chi^2_{(k-1)(p-1)}$ si $H_0$ es cierta.

\begin{remark}
    Este estadístico coincide con el que utilizábamos en el contraste de homogeneidad.
\end{remark}

Rechazaremos $H_0$ a nivel de significación $\alpha$ si:
$$\sum_{j=1}^p \sum_{i=1}^k \frac{(O_{ij}-e_{ij})^2}{e_{ij}} > \chi^2_{(k-1)(p-1), 1-\alpha}$$
En caso contrario, aceptaremos $H_0$ a nivel de significación $\alpha$.

% Ejemplos